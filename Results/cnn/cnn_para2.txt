"D:\Python Workspace\CLIP\clip\venv\Scripts\python.exe" "E:/01 - Northeastern/2024 Spring/01 - Data Science/Final Project/Neural Networks/cnn/cnn_para2.py"
cuda
Epoch 1, loss: 0.01379643860451393
Epoch 2, loss: 0.007191223695782305
Epoch 3, loss: 0.006118316949455797
Epoch 4, loss: 0.004870813427464137
Epoch 5, loss: 0.004953033251996415
Epoch 6, loss: 0.0037463628341072052
Epoch 7, loss: 0.003118404176917944
Epoch 8, loss: 0.0031497324370195665
Epoch 9, loss: 0.002593749136348242
Epoch 10, loss: 0.002415757110839898
Epoch 11, loss: 0.0020463809078569103
Epoch 12, loss: 0.0022609285438258122
Epoch 13, loss: 0.0019860923690883923
Epoch 14, loss: 0.0018499441065503964
Epoch 15, loss: 0.002621364200112108
Epoch 16, loss: 0.0014636358374995673
Epoch 17, loss: 0.0014039917963881367
Epoch 18, loss: 0.001671179158743527
Epoch 19, loss: 0.0013074105005355676
Epoch 20, loss: 0.0012740058882016404
Epoch 21, loss: 0.0015838843520465133
Epoch 22, loss: 0.0011870712859874618
Epoch 23, loss: 0.0011642097487685088
Epoch 24, loss: 0.0012435061142041883
Epoch 25, loss: 0.001564018430461488
Epoch 26, loss: 0.001037944502611654
Epoch 27, loss: 0.0010719503565667487
Epoch 28, loss: 0.0008312529243645606
Epoch 29, loss: 0.001280895528232046
Epoch 30, loss: 0.0007547722908954032
Epoch 31, loss: 0.0012876240710339086
Epoch 32, loss: 0.0012206384560976217
Epoch 33, loss: 0.000929386492479623
Epoch 34, loss: 0.0006579608370245241
Epoch 35, loss: 0.0009082799066284138
Epoch 36, loss: 0.0007678645023970044
Epoch 37, loss: 0.0015746166184857858
Epoch 38, loss: 0.0008110824661326205
Epoch 39, loss: 0.0005858524484926992
Epoch 40, loss: 0.0011839726925587427
Epoch 41, loss: 0.0006390411438838555
Epoch 42, loss: 0.0006908232205295381
Epoch 43, loss: 0.0019155884648413158
Epoch 44, loss: 0.0007003745728595898
Epoch 45, loss: 0.0016109107589796763
Epoch 46, loss: 0.002276875334688775
Epoch 47, loss: 0.000984780832895619
Epoch 48, loss: 0.000802857062012758
Epoch 49, loss: 0.0012446911672084325
Epoch 50, loss: 0.0008111655820517757
Epoch 51, loss: 0.0007933903320420576
Epoch 52, loss: 0.0015817173173832359
Epoch 53, loss: 0.0008253179365745568
Epoch 54, loss: 0.0016709150464202162
Epoch 55, loss: 0.0012124812722933873
Epoch 56, loss: 0.0007342325655764758
Epoch 57, loss: 0.0008826213688316695
Epoch 58, loss: 0.0015012639743245085
Epoch 59, loss: 0.0007560624890813585
Epoch 60, loss: 0.0008268974328257183
Epoch 61, loss: 0.0008467712672798549
Epoch 62, loss: 0.00069412628049708
Epoch 63, loss: 0.0011413094873089758
Epoch 64, loss: 0.0010571630655793111
Epoch 65, loss: 0.0005303518534735754
Epoch 66, loss: 0.0007851650112443427
Epoch 67, loss: 0.0003751805688181043
Epoch 68, loss: 0.0017193613403783383
Epoch 69, loss: 0.0005220722621440223
Epoch 70, loss: 0.0011812885431903173
Epoch 71, loss: 0.0007348661717330163
Epoch 72, loss: 0.002090883577464485
Epoch 73, loss: 0.0002526560344083307
Epoch 74, loss: 0.0011826637078198518
Epoch 75, loss: 0.0007047069717475579
Finished Training
              precision    recall  f1-score   support

           0     0.9996    0.9997    0.9996    281501
           1     0.9648    0.9552    0.9600      2815

    accuracy                         0.9992    284316
   macro avg     0.9822    0.9774    0.9798    284316
weighted avg     0.9992    0.9992    0.9992    284316

Savings: 0.9542937675269714

进程已结束,退出代码0
