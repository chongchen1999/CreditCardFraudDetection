"D:\Python Workspace\CLIP\clip\venv\Scripts\python.exe" "E:/01 - Northeastern/2024 Spring/01 - Data Science/Final Project/Neural Networks/cnn/cnn_para1.py"
cuda
Epoch 1, loss: 0.013423311608318009
Epoch 2, loss: 0.007207225533514711
Epoch 3, loss: 0.005648685380071905
Epoch 4, loss: 0.004763718450848788
Epoch 5, loss: 0.004174522879604482
Epoch 6, loss: 0.003504159545968487
Epoch 7, loss: 0.0027674440341054576
Epoch 8, loss: 0.0025660587045099087
Epoch 9, loss: 0.002244657702765156
Epoch 10, loss: 0.0021915495449144214
Epoch 11, loss: 0.001510233660722928
Epoch 12, loss: 0.002094955297821554
Epoch 13, loss: 0.0014777644806702468
Epoch 14, loss: 0.0014523816247855854
Epoch 15, loss: 0.0016817288941247581
Epoch 16, loss: 0.0012939660478640514
Epoch 17, loss: 0.0010742907298267653
Epoch 18, loss: 0.0012521584991307937
Epoch 19, loss: 0.0009248722497056856
Epoch 20, loss: 0.0011049318308850686
Epoch 21, loss: 0.001158194941456434
Epoch 22, loss: 0.0009402107052488111
Epoch 23, loss: 0.0012829825937696942
Epoch 24, loss: 0.0007572308537788438
Epoch 25, loss: 0.0013149735634378444
Epoch 26, loss: 0.0008478653154293454
Epoch 27, loss: 0.0008189048205254442
Epoch 28, loss: 0.0008570389452600093
Epoch 29, loss: 0.0007755863478330658
Epoch 30, loss: 0.00128932370649352
Epoch 31, loss: 0.0006709283706249502
Epoch 32, loss: 0.0008673108285321495
Epoch 33, loss: 0.002126001850378303
Epoch 34, loss: 0.0006228083275889674
Epoch 35, loss: 0.0011456807066413258
Epoch 36, loss: 0.000750149102433634
Epoch 37, loss: 0.0014832041746308776
Epoch 38, loss: 0.0007527702292707354
Epoch 39, loss: 0.0009021973111316023
Epoch 40, loss: 0.0005374639420014833
Epoch 41, loss: 0.0005374565229941091
Epoch 42, loss: 0.001089715994619451
Epoch 43, loss: 0.0004292348908052633
Epoch 44, loss: 0.0006344559033425915
Epoch 45, loss: 0.0009169205880759472
Epoch 46, loss: 0.00039582640221124305
Epoch 47, loss: 0.0008256875072195808
Epoch 48, loss: 0.0007369803575523504
Epoch 49, loss: 0.0006372308139573492
Epoch 50, loss: 0.000726323141961736
Epoch 51, loss: 0.0004273348027182687
Epoch 52, loss: 0.0010938673422033795
Epoch 53, loss: 0.0007315216435280178
Epoch 54, loss: 0.0005095554717726572
Epoch 55, loss: 0.0006308203856561084
Epoch 56, loss: 0.00041591255640191944
Epoch 57, loss: 0.0010794294127795074
Epoch 58, loss: 0.000639815766042094
Epoch 59, loss: 0.0008037960162686417
Epoch 60, loss: 0.001167739451778667
Epoch 61, loss: 0.0006081595129477617
Epoch 62, loss: 0.0006404352255519077
Epoch 63, loss: 0.0005425868615199031
Epoch 64, loss: 0.0011080031459603005
Epoch 65, loss: 0.0008012463110168379
Epoch 66, loss: 0.0010707913077879043
Epoch 67, loss: 0.0006351713078603629
Epoch 68, loss: 0.0006473628475025127
Epoch 69, loss: 0.0005772188183271687
Epoch 70, loss: 0.0003623128531129328
Epoch 71, loss: 0.0008755280475845096
Epoch 72, loss: 0.0006226384032700957
Epoch 73, loss: 0.0007807958643661315
Epoch 74, loss: 0.0006050683402352261
Epoch 75, loss: 0.0007472072330114703
Finished Training
              precision    recall  f1-score   support

           0     0.9998    0.9996    0.9997    281501
           1     0.9588    0.9758    0.9673      2815

    accuracy                         0.9993    284316
   macro avg     0.9793    0.9877    0.9835    284316
weighted avg     0.9994    0.9993    0.9993    284316

Savings: 0.9727589984889587

进程已结束,退出代码0
